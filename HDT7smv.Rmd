---
title: "HDT7SVM"
author: "Ayleen Rubio 19003, Andrés Say 19705, Andreé Toledo 18439"
date: "19/4/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#Ingebor Rubio/Desktop/Trabajos/Quinto Semestre/Mineria/HDT7SVM
#"C:/Users/Andreé Toledo/Documents/GitHub/HDT7SVM"

knitr::opts_knit$set(root.dir="C:/Users/Andreé Toledo/Documents/GitHub/HDT7SVM")
```

# Hoja de Trabajo No. 7: Máquinas Vectoriales de Soporte

En esta hoja de trabajo se busca poder clasificar una casa según su precio de venta, esto en tres posibles rangos: económicas, intermedias y caras. Para hacer esta predicción se buscará un modelo de SVM que haga una mejor clasificación, por lo que se han escogido las variables numéricas para plantear los modelos.

```{r data, echo=FALSE}
datosCasas <- read.csv("train.csv")
library(caret)
library(e1071)
library(tree)
library(randomForest)
install.packages("e1071")

porciento <- 70/100

set.seed(123)

datosCasas$clasificacion <- ifelse(datosCasas$SalePrice <= 251000, "Economicas", ifelse(datosCasas$SalePrice <= 538000, "Intermedias", ifelse(datosCasas$SalePrice <= 755000, "Caras")))

datosCasas$y <- factor(datosCasas$clasificacion)
datos <- datosCasas[,c(2,4,18,19,20,21,27,35,37,38,39,44,45,46,47,48,49,50,51,52,53,55,57,60,62,63,67,68,69,70,71,72,76,77,78,83)]
datos <- datos[,colSums(is.na(datos))==0]

trainRowsNumber<-sample(nrow(datos),porciento*nrow(datos))
train<-datos[trainRowsNumber,]
test<-datos[-trainRowsNumber,]
```

Luego de escoger los grupos de entrenamiento y prueba, se planteará el modelo:

```{r modelo, echo=FALSE}
modelosvm <- svm(y~., data = train, scale = F)
#View(test)
summary(modelosvm)
modelosvm$index
plot(modelosvm,train,GrLivArea~GarageArea)
#plot(modelosvm,train,Petal.Length~Sepal.Length)"
```

Puede observarse que el tipo de kernel utilizado es el radial, con un costo de 1, un valor de gamma de 0.031 y un valor de epsilon de 0.1, todo esto con 1021 vectores de soporte. Adicionalmente, se puede observar que en la gráfica mostrada, el modelo clasifica la mayoría de las casas como económicas 
A continuación se hará la generación de diferentes modelos.

```{r model2, echo=FALSE}
modelosSVM_L <-svm(y~. , data = train, cost = 2^5, kernel = "linear")
prediccionL<- predict(modelosSVM_L,newdata=test[,1:32])
confusionMatrix(test$y,prediccionL)
```

Con un modelo en el que el kernel es linear y el costo es 2^5, hemos tenido un porcentaje de acierto de 94.31%. En este caso se han clasificado incorrectamente 1 casa cara, 8 casas económicas y 16 casas intermedias, cometiendo un total de 25 errores.

```{r model3, echo=FALSE}
modelosSVM_L <-svm(y~. , data = train, cost = 2^-5, kernel = "linear")
prediccionL<- predict(modelosSVM_L,newdata=test[,1:32])
confusionMatrix(test$y,prediccionL)
```

Con un modelo en el que el kernel es linear y el costo es 2^-5, hemos tenido un porcentaje de acierto de 94.53%. En este caso se han clasificado incorrectamente 1 casa cara, 5 casas económicas y 18 casas intermedias, cometiendo un total de 24 errores.

```{r model4, echo=FALSE}
modelosSVM_L <-svm(y~. , data = train, cost = 0.5, kernel = "linear")
prediccionL<- predict(modelosSVM_L,newdata=test[,1:32])
confusionMatrix(test$y,prediccionL)
```

Con un modelo en el que el kernel es linear y el costo es 0.5, hemos tenido un porcentaje de acierto de 94.99%. En este caso se han clasficiado incorrectamente 1 casa cara, 6 casas económicas y 15 casas intermedias, cometiendo un total de 22 errores, este es el modelo lineal que menos errores ha cometido.

```{r model5, echo=FALSE}
modelosSVM_R <-svm(y~. , data = train, cost = 2^-5, kernel = "radial")
prediccionR<- predict(modelosSVM_R,newdata=test[,1:32])
confusionMatrix(test$y,prediccionR)
```

Con un modelo en el que el kernel es radial y el costo es 2^-5, hemos tenido un porcentaje de acierto de 84.74%. En este caso se ha cometido errores al clasificar 1 casa cara y 66 casas intermedias, en este modelo se han cometido 67 errores, clasificando todas como económicas.

```{r model6, echo=FALSE}
modelosSVM_R <-svm(y~. , data = train, cost = 2^1, kernel = "radial")
prediccionR<- predict(modelosSVM_R,newdata=test[,1:32])
confusionMatrix(test$y,prediccionR)
```

Con un modelo en el que el kernel es radial y el costo es 2^1, hemos tenido un porcentaje de acierto de 94.53%. En este caso se han cometido errores al clasificar 1 casa cara, 6 casas económicas y 17 casas intermedias, contando con un total de 24 errores, por lo que es el que mejor predice de los lineales, pero aún no llegar a predecir mejor que cualquier otro modelo.

Luego de haber hecho distintos modelos, podemos concluir que el que tiene un porcentaje de acierto más alto, 94.99%, es el que utiliza un kernel lineal con un costo de 0.5, por lo que utilizaremos este modelo como reeferencia.

A continuación se hará un modelo tuneado con diferentes valores de costo, utilizando un modelo lineal ya que es el que ha demostrado hacer une mejor predicción.

```{r modelDef, echo=FALSE}
modeloTuneado <- tune.svm(y~. , data = train, cost = c(0.01,0.1,0.5,1,5,10,16,20,32), kernel = "linear")
predMejorModelo <- predict(modeloTuneado$best.model, newdata = test[,1:32])
confusionMatrix(test$y, predMejorModelo)
```

Con el modelo tuneado, que es el que se basa en el mejor modelo, hemos tenido un porcentaje de acierto de 94.31%, se han cometido errores en la prediccion de 1 casa cara, 7 casas económicas y 17 casas intermedias, cometiendo un total de 25 errores.

Podemos observar que, igualmente, se sigue manteniendo como mejor modelo el que utiliza un kernel lineal con un costo de 0.5, con un porcentaje de acierto de 94.99%.

```{r modeloConclusion, echo=FALSE}
#View(train)
plot(modelosSVM_L,train,GrLivArea~GarageArea)


```

```{r arboles , echo=FALSE}
datosCasas <- read.csv("train.csv")
set.seed(71)
iris.rf <- randomForest(Species ~ ., data=iris, importance=TRUE,
                        proximity=TRUE)
print(iris.rf)

```

Realizando la misma gráfica del comienzo con el modelo más óptimo, se puede notar que en su mayoría sigue clasificando gran cantidad de las casas como económicas.

## Comparación
El mejor modelo fue el modelo 4 kernel lineal, que tiene un accuracy de 0.9499. a comparación del Random Forest que poseía un accuracy del 0.985, el algoritmo de bayes mostró 0.467 y el arbol de decisión en 0.8491.

En cuanto al árbol de regresión prsenta una precisión del 0.0109% lo cual indica que es una precisión muy mala debido a que el árbol trata de predecir el precio exacto de la casa. En comparación a SVM con kernel, demuestran que al ser tan buenos con la clasificación  de datos usando el hiperplano para separar los datos en más de dos dimensiones.

El árbol de clasificación por su parte, existe una mejora ya que no trata de ser tan exacto y se demuestra en el 70% de precisión pero comparado al método SVM sigue siendo mejor en cada variante de kernels donde muestra valores arriba del 85%.

Por último, random forest es el mejor árbol ya que se obtuvo un resultado más favorable con una precisión de 83.01%, aún así SVM continua superandólo en precisión.

## Informe de resultados

Calculando el porcentaje de eficiencia de los métodos, SVM tienen 96%  y 94% de eficiencia, por otro lado el método Naive Bayes tienen 73% de aciertos. En este ejemplo se observa que el método es eficiente para hacer clasificaciones, en este último ejemplo se tienen 58 variables no todas siguen comportamientos lineales, por lo cual tomar un kernel no lineal para  SVM  resulta apropiado.

Lo que se observa es que SVM puede servir como un método de clasificación para dos clases, pero también es adecuado para construir un modelo para clasificar para más de dos clases.