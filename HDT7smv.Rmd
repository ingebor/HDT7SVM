---
title: "HDT7SVM"
author: "Ayleen Rubio 19003, Andrés Say 19705, Andreé Toledo 18439"
date: "19/4/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#Ingebor Rubio/Desktop/Trabajos/Quinto Semestre/Mineria/HDT7SVM

knitr::opts_knit$set(root.dir="C:/Users/andre/OneDrive/Documentos/3er año/1er semestre/Minería de datos/proyecto/HDT7SVM")
```

# Hoja de Trabajo No. 7: Máquinas Vectoriales de Soporte

En esta hoja de trabajo se busca poder clasificar una casa según su precio de venta, esto en tres posibles rangos: económicas, intermedias y caras. Para hacer esta predicción se buscará un modelo de SVM que haga una mejor clasificación, por lo que se han escogido las variables numéricas para plantear los modelos.

```{r data, echo=FALSE}
datosCasas <- read.csv("train.csv")
library(caret)
library(e1071)

porciento <- 70/100

set.seed(123)

datosCasas$clasificacion <- ifelse(datosCasas$SalePrice <= 251000, "Economicas", ifelse(datosCasas$SalePrice <= 538000, "Intermedias", ifelse(datosCasas$SalePrice <= 755000, "Caras")))

datosCasas$y <- factor(datosCasas$clasificacion)
datos <- datosCasas[,c(2,4,18,19,20,21,27,35,37,38,39,44,45,46,47,48,49,50,51,52,53,55,57,60,62,63,67,68,69,70,71,72,76,77,78,83)]
datos <- datos[,colSums(is.na(datos))==0]

trainRowsNumber<-sample(nrow(datos),porciento*nrow(datos))
train<-datos[trainRowsNumber,]
test<-datos[-trainRowsNumber,]
```

Luego de escoger los grupos de entrenamiento y prueba, se planteará el modelo:

```{r modelo, echo=FALSE}
modelosvm <- svm(y~., data = train, scale = F)
#View(test)
summary(modelosvm)
modelosvm$index
plot(modelosvm,train,GrLivArea~GarageArea)
#plot(modelosvm,train,Petal.Length~Sepal.Length)"
```

Puede observarse que el tipo de kernel utilizado es el radial, con un costo de 1, un valor de gamma de 0.031 y un valor de epsilon de 0.1, todo esto con 1021 vectores de soporte. Adicionalmente, se puede observar que en la gráfica mostrada, el modelo clasifica la mayoría de las casas como económicas 
A continuación se hará la generación de diferentes modelos.

```{r model2, echo=FALSE}
modelosSVM_L <-svm(y~. , data = train, cost = 2^5, kernel = "linear")
prediccionL<- predict(modelosSVM_L,newdata=test[,1:32])
confusionMatrix(test$y,prediccionL)
```

Con un modelo en el que el kernel es linear y el costo es 2^5, hemos tenido un porcentaje de acierto de 94.31%. En este caso se han clasificado incorrectamente 1 casa cara, 8 casas económicas y 16 casas intermedias, cometiendo un total de 25 errores.

```{r model3, echo=FALSE}
modelosSVM_L <-svm(y~. , data = train, cost = 2^-5, kernel = "linear")
prediccionL<- predict(modelosSVM_L,newdata=test[,1:32])
confusionMatrix(test$y,prediccionL)
```

Con un modelo en el que el kernel es linear y el costo es 2^-5, hemos tenido un porcentaje de acierto de 94.53%. En este caso se han clasificado incorrectamente 1 casa cara, 5 casas económicas y 18 casas intermedias, cometiendo un total de 24 errores.

```{r model4, echo=FALSE}
modelosSVM_L <-svm(y~. , data = train, cost = 0.5, kernel = "linear")
prediccionL<- predict(modelosSVM_L,newdata=test[,1:32])
confusionMatrix(test$y,prediccionL)
```

Con un modelo en el que el kernel es linear y el costo es 0.5, hemos tenido un porcentaje de acierto de 94.99%. En este caso se han clasficiado incorrectamente 1 casa cara, 6 casas económicas y 15 casas intermedias, cometiendo un total de 22 errores, este es el modelo lineal que menos errores ha cometido.

```{r model5, echo=FALSE}
modelosSVM_R <-svm(y~. , data = train, cost = 2^-5, kernel = "radial")
prediccionR<- predict(modelosSVM_R,newdata=test[,1:32])
confusionMatrix(test$y,prediccionR)
```

Con un modelo en el que el kernel es radial y el costo es 2^-5, hemos tenido un porcentaje de acierto de 84.74%. En este caso se ha cometido errores al clasificar 1 casa cara y 66 casas intermedias, en este modelo se han cometido 67 errores, clasificando todas como económicas.

```{r model6, echo=FALSE}
modelosSVM_R <-svm(y~. , data = train, cost = 2^1, kernel = "radial")
prediccionR<- predict(modelosSVM_R,newdata=test[,1:32])
confusionMatrix(test$y,prediccionR)
```

Con un modelo en el que el kernel es radial y el costo es 2^1, hemos tenido un porcentaje de acierto de 94.53%. En este caso se han cometido errores al clasificar 1 casa cara, 6 casas económicas y 17 casas intermedias, contando con un total de 24 errores, por lo que es el que mejor predice de los lineales, pero aún no llegar a predecir mejor que cualquier otro modelo.

Luego de haber hecho distintos modelos, podemos concluir que el que tiene un porcentaje de acierto más alto, 94.99%, es el que utiliza un kernel lineal con un costo de 0.5, por lo que utilizaremos este modelo como reeferencia.

A continuación se hará un modelo tuneado con diferentes valores de costo, utilizando un modelo lineal ya que es el que ha demostrado hacer une mejor predicción.

```{r modelDef, echo=FALSE}
modeloTuneado <- tune.svm(y~. , data = train, cost = c(0.01,0.1,0.5,1,5,10,16,20,32), kernel = "linear")
predMejorModelo <- predict(modeloTuneado$best.model, newdata = test[,1:32])
confusionMatrix(test$y, predMejorModelo)
```

Con el modelo tuneado, que es el que se basa en el mejor modelo, hemos tenido un porcentaje de acierto de 94.31%, se han cometido errores en la prediccion de 1 casa cara, 7 casas económicas y 17 casas intermedias, cometiendo un total de 25 errores.

Podemos observar que, igualmente, se sigue manteniendo como mejor modelo el que utiliza un kernel lineal con un costo de 0.5, con un porcentaje de acierto de 94.99%.

```{r modeloConclusion, echo=FALSE}
#View(train)
plot(modelosSVM_L,train,GrLivArea~GarageArea)
```

Realizando la misma gráfica del comienzo con el modelo más óptimo, se puede notar que en su mayoría sigue clasificando gran cantidad de las casas como económicas.

## comparacion
El mejor modelo fue el modelo 4 kernel lineal, que tiene un accuracy de 0.9499. a comparación del Random Forest que poseía un accuracy del 0.985, el algoritmo de bayes mostró 0.467 y el arbol de decisión (este falta Andreé no lo encontré)

## Informe de resultados